<!DOCTYPE html>
<html lang="zh-CN">

  
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  
  
  <title>Hadoop之MapReduce | shaohua&#39;s blog</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="大数据,Hadoop,">
  

  <script type="text/javascript">
	$(document).ready(function() {
	    //为超链接加上target='_blank'属性
		$('a[href^="http"]').each(function() {
			$(this).attr('target', '_blank');
		});
	});
  </script>

  

  

  
    <link rel="icon" href="/images/favicon.ico">
    <link rel="apple-touch-icon" href="/images/touch-icon.png">
  

  <link href="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/base.css">
<link rel="stylesheet" href="/icon/iconfont.css">
<link rel="stylesheet" href="/css/github-markdown.css">
<link rel="stylesheet" href="/css/highlight.css">

  <script src="/js/util.js"></script>
<script src="/js/valine.min.js"></script>

  

  
    <link href="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.css" rel="stylesheet">
    <script src="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.js" async></script>
  

  
  
  <script src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js" async></script>
  
  

</head>

  <body>

    

    <div id="app">

      <div class="header-wrap">
  <header>
    <div class="site-brand">
      <div class="site-title">
        <a href="/">Fenghuayangyi</a>
      </div>
    </div>
    <nav class="site-navigation">
      <ul class="nav-menu">
      
        <li class="nav-item" data-path="/">
          
            <a href="/" target="_self">
              主页
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/archives/">
          
            <a href="/archives/" target="_self">
              归档
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/categories/">
          
            <a href="/categories/" target="_self">
              分类
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/tags/">
          
            <a href="/tags/" target="_self">
              标签
            </a>
          
        </li>
      
        <li class="nav-item" data-path>
          
            <a href="javascript:void(0);" v-else>抓到我</a>
            <ul class="nav-menu--dropdown">
              
                <li>
                  <a href="https://github.com/fenghuayangyi" target="_blank">
                    Github
                  </a>
                </li>
              
                <li>
                  <a href="https://blog.csdn.net/u011295626" target="_blank">
                    CSDN
                  </a>
                </li>
              
            </ul>
          
        </li>
      
      </ul>
    </nav>
    <i class="iconfont icon-menu"></i>
  </header>
</div>

<script>
  let links = document.querySelectorAll('.nav-item');
  for(let link of links){
    let childrenLink = link.querySelector('ul');
    link.addEventListener('mouseenter', () => {
      if(childrenLink) {
        childrenLink.className = "nav-menu--dropdown active";
      }
    })
    link.addEventListener('mouseleave', () => {
      if(childrenLink) {
        childrenLink.className = "nav-menu--dropdown";
      }
    })
  }
  let rootRealPath = getRealPath(window.location.pathname, true);
  for(let link of links) {
    let linkPath = link.getAttribute("data-path");
    if(linkPath && getRealPath(linkPath, true) === rootRealPath) {
      link.className = "nav-item hover";
    }
  }

  let iconMenu = document.querySelector("i.iconfont.icon-menu"),
    iconMenuClicked = false;
  let navDOM = document.querySelector("nav.site-navigation");
  iconMenu.addEventListener("click", () => {
    iconMenuClicked 
      ? navDOM.className = "site-navigation active"
      : navDOM.className = "site-navigation";
    iconMenuClicked = !iconMenuClicked;
  })
</script>

      








<div class="container post-index">

  

<div class="post">
  <h1 class="article-title">
    <span>Hadoop之MapReduce</span>
  </h1>
  <div class="article-top-meta">
    <span>
      发布 : 
      2019-04-12
    </span>
    
      <span>
        分类 : 
          <a href="/categories/大数据/">
            大数据
          </a>
      </span>
    
    
  </div>

  

  <div class="article-content">
    <div class="markdown-body">
      <h1 id="MapReduce概述"><a href="#MapReduce概述" class="headerlink" title="MapReduce概述"></a>MapReduce概述</h1><p>##1. MapReduce分布式方案考虑的问题</p>
<p>​    （1）运算逻辑要不要先分后合？ </p>
<p>​    （2）程序如何分配运算任务（切片）？</p>
<p>​    （3）两阶段的程序如何启动？如何协调？</p>
<p>​    （4）整个程序运行过程中的监控？容错？重试？</p>
<p>​    分布式方案需要考虑很多问题，但是我们可以将分布式程序中的公共功能封装成框        架，让开发人员将精力集中于业务逻辑上。而mapreduce就是这样一个分布式程序的通用框架。</p>
<h2 id="2-MapReduce核心思想"><a href="#2-MapReduce核心思想" class="headerlink" title="2. MapReduce核心思想"></a>2. MapReduce核心思想</h2><p>以wordcount为例：</p>
<p>需求：统计文件中每一个单词出现的总次数（查询结果a-p一个文件, q-z一个文件）</p>
<p><img src="http://ww1.sinaimg.cn/large/a3a0cfd7ly1g7hc9qijgdj211p0eggn3.jpg" alt="mapreduce流程.jpg"></p>
<ul>
<li><p>总述：</p>
<p>1）分布式的运算程序往往需要分成至少2个阶段</p>
<p>2）第一个阶段的maptask并发实例，完全并行运行，互不相干</p>
<p>3）第二个阶段的reduce task并发实例互不相干，但是他们的数据依赖于上一个阶段的所有maptask并发实例的输出</p>
<p>4）MapReduce编程模型只能包含一个map阶段和一个reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个mapreduce程序，串行运行</p>
</li>
<li><p>若干细节问题：</p>
<ol>
<li>Map task 如何进行任务分配</li>
<li>Reduce task 如何进行任务分配</li>
<li>Map task 和 Reduce task 如何衔接</li>
<li>Map task 如何都要自己负责数据的分区，很麻烦</li>
</ol>
</li>
</ul>
<h2 id="3-MapReduce-进程"><a href="#3-MapReduce-进程" class="headerlink" title="3. MapReduce 进程"></a>3. MapReduce 进程</h2><p>一个完整的mapreduce程序在分布式运行时有三类实例进程：</p>
<ol>
<li>MrAppMaster: 负责整个程序的过程调度以及状态协调。</li>
<li>MapTask: 负责map阶段的整个数据处理流程。</li>
<li>ReduceTask：负责Reduce阶段的整个数据处理流程。</li>
</ol>
<h2 id="4-MapReduce-编程规范"><a href="#4-MapReduce-编程规范" class="headerlink" title="4. MapReduce 编程规范"></a>4. MapReduce 编程规范</h2><p>户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行mr程序的客户端)</p>
<p>1）Mapper阶段</p>
<p>​       （1）用户自定义的Mapper要继承自己的父类</p>
<p>​       （2）Mapper的输入数据是KV对的形式（KV的类型可自定义）</p>
<p>​       （3）Mapper中的业务逻辑写在map()方法中</p>
<p>​       （4）Mapper的输出数据是KV对的形式（KV的类型可自定义）</p>
<p>​       （5）<strong>map()方法（maptask进程）对每一个&lt;K,V&gt;调用一次</strong></p>
<p>2）Reducer阶段</p>
<p>​       （1）用户自定义的Reducer要继承自己的父类</p>
<p>​       （2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV</p>
<p>​       （3）Reducer的业务逻辑写在reduce()方法中</p>
<p>​       （4）<strong>Reducetask进程对每一组相同k的&lt;k,v&gt;组调用一次reduce()方法</strong></p>
<p>3）Driver阶段</p>
<p>​      整个程序需要一个Drvier来进行提交，提交的是一个描述了各种必要信息的job对象</p>
<h2 id="5-MapReduce程序运行流程分析"><a href="#5-MapReduce程序运行流程分析" class="headerlink" title="5. MapReduce程序运行流程分析"></a>5. MapReduce程序运行流程分析</h2><p>​    1）在MapReduce程序读取文件的输入目录上存放相应的文件。</p>
<p>​    2）客户端程序在submit()方法执行前，获取待处理的数据信息，然后根据集群中参数的配置形成一个任务分配规划。</p>
<p>​    3）客户端提交job.split、jar包、job.xml等文件给yarn，yarn中resourcemanager启动MRAppMaster。</p>
<p>​    4）MRAppMaster启动后根据本次job的描述信息，计算出需要的maptask实例数量，然后向集群申请机器启动相应数量的maptask进程。</p>
<p>​    5）maptask利用客户指定的inputformat来读取数据，形成输入KV对。</p>
<p>​    6）maptask将输入KV对传递给客户定义的map()方法，做逻辑运算</p>
<p>​    7）<strong>map()运算完毕后将KV对收集到maptask缓存</strong>。</p>
<p>​    8）<strong>maptask缓存中的KV对   <em>按照K分区排序</em>   后不断写到磁盘文件</strong></p>
<p>​    9）MRAppMaster监控到所有maptask进程任务完成之后，<strong>会根据客户指定的参数启动相应数量的reducetask进程</strong>，并告知reducetask进程要处理的数据分区。</p>
<p>​    10）Reducetask进程启动之后，根据MRAppMaster告知的待处理数据所在位置，<strong>从若干台maptask运行所在机器上获取到若干个maptask输出结果文件</strong>，并在本地进行<strong>重新归并排序</strong>，然后按照<strong>相同key的KV为一个组</strong>，<strong>调用客户定义的reduce()方法</strong>进行逻辑运算。</p>
<p>​    11）Reducetask运算完毕后，调用客户指定的outputformat将结果数据输出到外部存储。</p>
<h1 id="框架原理"><a href="#框架原理" class="headerlink" title="框架原理"></a>框架原理</h1><h2 id="1-MapReduce工作流程"><a href="#1-MapReduce工作流程" class="headerlink" title="1. MapReduce工作流程"></a>1. MapReduce工作流程</h2><ul>
<li><p><strong>流程步骤</strong></p>
<ol>
<li><p>待处理文本</p>
</li>
<li><p>客户端程序在submit()方法执行前，获取待处理的数据信息，然后根据集群中参数的配置形成一个任务分配规划。</p>
<p>如： test1.txt 0-128</p>
<p>​    test1.txt 128-240</p>
<p>​    test2.txt</p>
</li>
<li><p>提交切片信息（客户端提交job.split、jar包、job.xml等文件给yarn）</p>
</li>
<li><p>计算出maptask的数量</p>
</li>
<li><p>根据inputformat来读取数据</p>
</li>
<li><p>map(),进行逻辑运算</p>
</li>
<li><p>运算完毕后将KV对收集到maptask缓存（默认100M）</p>
</li>
<li><p>根据key分区，排序</p>
</li>
<li><p>缓冲区溢出，写入文件（分区且区内有序）</p>
</li>
<li><p>归并排序，将溢出的文件合并成大文件</p>
</li>
<li><p>所有map任务完成后，启动相应数量的reducetask, 并告知reducetask处理数据的范围（数据分区）</p>
</li>
<li><p>reducetask下载待处理数据到本地磁盘</p>
</li>
<li><p>归并排序，合并文件</p>
</li>
<li><p>一次读取一组</p>
</li>
<li><p>分组（groupingComparator）</p>
</li>
<li><p>outputformat将结果数据输出到外部存储。</p>
</li>
</ol>
</li>
<li><p><strong>shuffle流程详解 (7-16步)</strong></p>
<p> 1）maptask收集我们的map()方法输出的kv对，放到内存缓冲区中</p>
<p> 2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</p>
<p> 3）多个溢出文件会被合并成大的溢出文件</p>
<p> <strong>4）在溢出过程中，及合并的过程中，都要调用partitioner进行分区和针对key进行排序</strong></p>
<p> <strong>5）reducetask根据自己的分区号，去各个maptask机器上取相应的结果分区数据</strong></p>
<p> <strong>6）reducetask会取到同一个分区的来自不同maptask的结果文件， reducetask会将这些文件再进行合并（归并排序）</strong></p>
<p> <strong>7）合并成大文件后，shuffle的过程也就结束了，后面进入reducetask的逻辑运算过程（从文件中取出一个一个的键值对group，调用用户自定义的reduce()方法）</strong></p>
</li>
<li><p><strong>注意</strong></p>
<p> Shuffle中的缓冲区大小会影响到mapreduce程序的执行效率，原则上说，<strong>缓冲区越大，磁盘io的次数越少，执行速度就越快。</strong></p>
<p><strong>缓冲区的大小可以通过参数调整，参数：io.sort.mb  默认100M</strong></p>
</li>
</ul>
<h2 id="2-Writable序列化"><a href="#2-Writable序列化" class="headerlink" title="2. Writable序列化"></a>2. Writable序列化</h2><p>​    序列化就是把内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储（持久化）和网络传输。 </p>
<p>​    反序列化就是将收到字节序列（或其他数据传输协议）或者是硬盘的持久化数据，转换成内存中的对象。</p>
<p>​    <strong>Java的序列化是一个重量级序列化框架（Serializable）</strong>，一个对象被序列化后，会附带很多额外的信息（各种校验信息，header，继承体系等），<strong>不便于在网络中高效传输</strong>。所以，<strong>hadoop自己开发了一套序列化机制（Writable），精简、高效。</strong></p>
<h3 id="2-1-常用数据序列化类型"><a href="#2-1-常用数据序列化类型" class="headerlink" title="2.1 常用数据序列化类型"></a>2.1 常用数据序列化类型</h3><p>常用的数据类型对应的hadoop数据序列化类型</p>
<p><img src="http://ww1.sinaimg.cn/large/a3a0cfd7gy1g7hgcxf913j20lt08o0su.jpg" alt="writable.jpg"></p>
<p>###　2.2 自定义bean对象实现序列化接口</p>
<ul>
<li><p>自定义bean对象要想序列化传输，必须实现序列化接口，需要注意以下7项。</p>
<p><strong>（1）必须实现Writable接口</strong></p>
<p><strong>（2）反序列化时，需要反射调用空参构造函数，所以<em>必须有空参构造</em></strong></p>
<p><strong>（3）重写序列化方法</strong></p>
<p><strong>（4）重写反序列化方法</strong></p>
<p><strong>（5）注意反序列化的顺序和序列化的顺序完全一致</strong></p>
<p><strong>（6）要想把结果显示在文件中，需要重写toString()，且用”\t”分开，方便后续用</strong></p>
<p><strong>（7）如果需要将自定义的bean放在key中传输，则还需要实现comparable接口，因为mapreduce框中的shuffle过程一定会对key进行排序</strong></p>
</li>
</ul>
<p>以统计每一个手机号耗费的总上行流量、下行流量、总流量（序列化），为例**</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">// 1 必须实现Writable接口</span><br><span class="line">public class FlowBean implements Writable &#123;</span><br><span class="line"></span><br><span class="line">	private long upFlow;</span><br><span class="line">	private long downFlow;</span><br><span class="line">	private long sumFlow;</span><br><span class="line"></span><br><span class="line">	//2 反序列化时，需要反射调用空参构造函数，所以必须有</span><br><span class="line">	public FlowBean() &#123;</span><br><span class="line">		super();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/**</span><br><span class="line">	 * 3重写序列化方法</span><br><span class="line">	 * </span><br><span class="line">	 * @param out</span><br><span class="line">	 * @throws IOException</span><br><span class="line">	 */</span><br><span class="line">	@Override</span><br><span class="line">	public void write(DataOutput out) throws IOException &#123;</span><br><span class="line">		out.writeLong(upFlow);</span><br><span class="line">		out.writeLong(downFlow);</span><br><span class="line">		out.writeLong(sumFlow);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/**</span><br><span class="line">	 * 4 重写反序列化方法 </span><br><span class="line">5 注意反序列化的顺序和序列化的顺序完全一致</span><br><span class="line">	 * </span><br><span class="line">	 * @param in</span><br><span class="line">	 * @throws IOException</span><br><span class="line">	 */</span><br><span class="line">	@Override</span><br><span class="line">	public void readFields(DataInput in) throws IOException &#123;</span><br><span class="line">		upFlow = in.readLong();</span><br><span class="line">		downFlow = in.readLong();</span><br><span class="line">		sumFlow = in.readLong();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    // 6要想把结果显示在文件中，需要重写toString()，且用”\t”分开，方便后续用</span><br><span class="line">	@Override</span><br><span class="line">	public String toString() &#123;</span><br><span class="line">		return upFlow + &quot;\t&quot; + downFlow + &quot;\t&quot; + sumFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">    //7 如果需要将自定义的bean放在key中传输，则还需要实现comparable接口，因为mapreduce框中的shuffle过程一定会对key进行排序</span><br><span class="line">	@Override</span><br><span class="line">	public int compareTo(FlowBean o) &#123;</span><br><span class="line">		// 倒序排列，从大到小</span><br><span class="line">		return this.sumFlow &gt; o.getSumFlow() ? -1 : 1;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-InputFormat数据切片机制"><a href="#3-InputFormat数据切片机制" class="headerlink" title="3. InputFormat数据切片机制"></a>3. InputFormat数据切片机制</h2><h3 id="3-1-job提交流程源码详解"><a href="#3-1-job提交流程源码详解" class="headerlink" title="3.1 job提交流程源码详解"></a>3.1 job提交流程源码详解</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">1）job提交流程源码详解</span><br><span class="line">waitForCompletion()</span><br><span class="line">submit();</span><br><span class="line">// 1建立连接</span><br><span class="line">	connect();	</span><br><span class="line">		// 1）创建提交job的代理</span><br><span class="line">		new Cluster(getConfiguration());</span><br><span class="line">		// 2）判断是本地yarn还是远程</span><br><span class="line">		initialize(jobTrackAddr, conf); </span><br><span class="line">// 2 提交job</span><br><span class="line">submitter.submitJobInternal(Job.this, cluster)</span><br><span class="line">	// 1）创建给集群提交数据的Stag路径</span><br><span class="line">	Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class="line">	// 2）获取jobid ，并创建job路径</span><br><span class="line">	JobID jobId = submitClient.getNewJobID();</span><br><span class="line">	// 3）拷贝jar包到集群</span><br><span class="line">copyAndConfigureFiles(job, submitJobDir);	</span><br><span class="line">	rUploader.uploadFiles(job, jobSubmitDir);</span><br><span class="line">// 4）计算切片，生成切片规划文件</span><br><span class="line">writeSplits(job, submitJobDir);</span><br><span class="line">	maps = writeNewSplits(job, jobSubmitDir);</span><br><span class="line">		input.getSplits(job);</span><br><span class="line">// 5）向Stag路径写xml配置文件</span><br><span class="line">writeConf(conf, submitJobFile);</span><br><span class="line">	conf.writeXml(out);</span><br><span class="line">// 6）提交job,返回提交状态</span><br><span class="line">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br></pre></td></tr></table></figure>
<h3 id="3-2-FileInputFormat源码解析-input-getSplits-job"><a href="#3-2-FileInputFormat源码解析-input-getSplits-job" class="headerlink" title="3.2 FileInputFormat源码解析(input.getSplits(job))"></a>3.2 FileInputFormat源码解析(input.getSplits(job))</h3><p><img src="http://ww1.sinaimg.cn/large/a3a0cfd7ly1g7hogzk5b0j20rc0ee3zq.jpg" alt="FileInputFormat.jpg"></p>
<p>（1）找到你数据存储的目录。</p>
<p>（2）开始遍历处理（规划切片）目录下的每一个文件</p>
<p>（3）遍历第一个文件ss.txt</p>
<p>​        a）获取文件大小fs.sizeOf(ss.txt);</p>
<p>​         b）计算切片大小        computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M</p>
<p>​        c）默认情况下，切片大小=blocksize</p>
<p>​                  d）开始切，形成第1个切片：ss.txt—0:128M第2个切片ss.txt—128:256M 第3个切片ss.txt—256M:300M（每次切片时，都要判断切完剩下的部分是否大于块的1.1倍，不大于1.1倍就划分一块切片）</p>
<p>​                  e）将切片信息写到一个切片规划文件中</p>
<p>​                  f）整个切片的核心过程在getSplit()方法中完成。</p>
<p>​         g）数据切片只是在逻辑上对输入数据进行分片，并不会再磁盘上将其切分成分片进行存储。InputSplit只记录了分片的元数据信息，比如起始位置、长度以及所在的节点列表等。</p>
<p>h）注意：block是HDFS上物理上存储的存储的数据，切片是对数据逻辑上的划分。</p>
<p>（4）提交切片规划文件到yarn上，yarn上的MrAppMaster就可以根据切片规划文件计算开启maptask个数。</p>
<h3 id="3-3-FileInputFormat中默认的切片机制："><a href="#3-3-FileInputFormat中默认的切片机制：" class="headerlink" title="3.3 FileInputFormat中默认的切片机制："></a>3.3 FileInputFormat中默认的切片机制：</h3><p>（1）简单地按照文件的内容长度进行切片</p>
<p>（2）切片大小，默认等于block大小</p>
<p>（3）切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</p>
<p>比如待处理数据有两个文件：</p>
<p>​    file1.txt    320M</p>
<p>​    file2.txt    10M</p>
<p>经过FileInputFormat的切片机制运算后，形成的切片信息如下：  </p>
<p>​    file1.txt.split1–  0~128</p>
<p>​    file1.txt.split2–  128~256</p>
<p>​    file1.txt.split3–  256~320</p>
<p>​    file2.txt.split1–  0~10M</p>
<h3 id="3-4-FileInputFormat切片大小的参数配置"><a href="#3-4-FileInputFormat切片大小的参数配置" class="headerlink" title="3.4 FileInputFormat切片大小的参数配置"></a>3.4 FileInputFormat切片大小的参数配置</h3><p>（1）通过分析源码，在FileInputFormat中，计算切片大小的逻辑：Math.max(minSize,Math.min(maxSize, blockSize));  </p>
<p>切片主要由这几个值来运算决定:</p>
<p>mapreduce.input.fileinputformat.split.minsize=1默认值为1</p>
<p>mapreduce.input.fileinputformat.split.maxsize=Long.MAXValue 默认值Long.MAXValue</p>
<p>因此，默认情况下，切片大小=blocksize。</p>
<p>​    maxsize（切片最大值）：参数如果调得比blocksize小，则会让切片变小，而且就等于配置的这个参数的值。</p>
<p>​    minsize（切片最小值）：参数调的比blockSize大，则可以让切片变得比blocksize还大。</p>
<p>（2）获取切片信息API</p>
<pre><code>// 根据文件类型获取切片信息
FileSplit inputSplit = (FileSplit) context.getInputSplit();
// 获取切片的文件名称
String name = inputSplit.getPath().getName();
</code></pre><h3 id="3-5-CombineTextInputFormat切片机制"><a href="#3-5-CombineTextInputFormat切片机制" class="headerlink" title="3.5 CombineTextInputFormat切片机制"></a>3.5 CombineTextInputFormat切片机制</h3><p>关于大量小文件的优化策略</p>
<p>1）默认情况下TextInputformat对任务的切片机制是按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个maptask，这样如果有大量小文件，就会产生大量的maptask，处理效率极其低下。</p>
<p>2）优化策略</p>
<p>​       （1）最好的办法，在数据处理系统的最前端（预处理/采集），将小文件先合并成大文件，再上传到HDFS做后续分析。</p>
<p>​       （2）补救措施：如果已经是大量小文件在HDFS中了，可以使用另一种InputFormat来做切片（CombineTextInputFormat），它的切片逻辑跟TextFileInputFormat不同：它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个maptask。</p>
<p>​       （3）优先满足最小切片大小，不超过最大切片大小</p>
<p>​              CombineTextInputFormat.<em>setMaxInputSplitSize</em>(job,4194304);// 128m</p>
<p>​              CombineTextInputFormat.<em>setMinInputSplitSize</em>(job,2097152);// 2m</p>
<p>​               举例：0.5m+1m+0.3m+5m=2m + 4.8m=2m + 4m + 0.8m</p>
<p>3）具体实现步骤</p>
<p>​    //如果不设置InputFormat,它默认用的是TextInputFormat.class</p>
<p>​    job.setInputFormatClass(CombineTextInputFormat.<strong>class</strong>)</p>
<p>​    CombineTextInputFormat.<em>setMaxInputSplitSize</em>(job,4194304);// 4m</p>
<p>​    CombineTextInputFormat.<em>setMinInputSplitSize</em>(job,2097152);// 2m</p>
<h3 id="3-6-自定义InputFormat"><a href="#3-6-自定义InputFormat" class="headerlink" title="3.6 自定义InputFormat"></a>3.6 自定义InputFormat</h3><p><strong>概述</strong></p>
<p>（1）自定义一个类继承FileInputFormat</p>
<p>（2）改写RecordReader，实现一次读取一个完整文件封装为KV</p>
<p>（3）在输出时使用SequenceFileOutPutFormat输出合并文件</p>
<h2 id="4-MapTask工作机制"><a href="#4-MapTask工作机制" class="headerlink" title="4. MapTask工作机制"></a>4. MapTask工作机制</h2><h2 id="5-Shuffle机制"><a href="#5-Shuffle机制" class="headerlink" title="5. Shuffle机制"></a>5. Shuffle机制</h2><h2 id="6-ReduceTask工作机制"><a href="#6-ReduceTask工作机制" class="headerlink" title="6. ReduceTask工作机制"></a>6. ReduceTask工作机制</h2><h2 id="7-自定义OutputFormat"><a href="#7-自定义OutputFormat" class="headerlink" title="7. 自定义OutputFormat"></a>7. 自定义OutputFormat</h2><h2 id="8-计数器应用"><a href="#8-计数器应用" class="headerlink" title="8. 计数器应用"></a>8. 计数器应用</h2><h2 id="9-数据清洗"><a href="#9-数据清洗" class="headerlink" title="9. 数据清洗"></a>9. 数据清洗</h2><h1 id="MapReduce与Yarn"><a href="#MapReduce与Yarn" class="headerlink" title="MapReduce与Yarn"></a>MapReduce与Yarn</h1>
    </div>
  </div>
  
    <div class="copy-right">
      <div class="markdown-body">
        <blockquote>
        
        
          本文作者 : fenghuayangyi <br>
        
        原文链接 : <a href>https://github.com/fenghuayangyi/2019/04/12/MapReduce/</a><br>
        版权声明 : 本博客采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。
        </blockquote>
      </div>
    </div>
  
  
  

  
    <div id="reward">
  
    <p id="reward-meta">知识 & 情怀 | 二者兼得</p>
  
  <button id="reward-btn">
    
    <span>投食</span>
  </button>
  <div id="reward-qrcode">
    
      <div class="reward-qrcode--container">
        <img class="qrcode-img" src="/images/wechat.png" alt="微信扫一扫, 向我投食">
        <p class="qrcode-meta">微信扫一扫, 向我投食</p>
      </div>
    
      <div class="reward-qrcode--container">
        <img class="qrcode-img" src="/images/alipay.png" alt="支付宝扫一扫, 向我投食">
        <p class="qrcode-meta">支付宝扫一扫, 向我投食</p>
      </div>
    
  </div>

</div>

<script>
  (() => {
    let button = document.querySelector('#reward-btn'),
      qrcode = document.querySelector('#reward-qrcode'),
      display = false;
    
    button.addEventListener('click', () => {
      qrcode.style.display = display ? 'none' : 'block'
      display = !display
    }, false)
  })()
</script>
  

  <div class="article-footer">
    <div class="article-meta pull-left">
      <span>
        
          <i class="iconfont icon-06tags"></i>标签: 
          
          <span class="span--tag">
            <a href="/tags/Hadoop/">
              #Hadoop
            </a>
          </span>
          
        
      </span>
    </div>
    <div class="article-meta pull-right">
    </div>
  </div>
</div>


  <aside id="sidebar">
    <p id="sidebar-header"></p>
    <ol id="sidebar-toc"></ol>
  </aside>
  <script async>setTimeout(generateToc, 10);</script>


  <nav class="post-navigation">
    
      <div class="nav-pre">
        <i class="iconfont icon-prev"></i>
        上一篇:
        <a href="/2019/03/04/刷题总结/" target="_self">面试准备之刷题总结</a>
      </div>
    
    
      <div class="nav-next">
        下一篇:
        <a href="/2019/04/22/Hive/" target="_self">Hive入门</a>
        <i class="iconfont icon-next"></i>
      </div>
    
  </nav>

   

   

</div>


      <footer>
  <p class="site-info">
    博客已运行<span id="time-to-now"></span><span class="my-face">(●'◡'●)ﾉ♥</span>
    
  </p>
</footer>



<script>
const timeToNowDOM = document.querySelector("#time-to-now");
const startTimestamp = new Date(2018, 11, 10).getTime();

const updateTimeStr = () => {
  let offset = parseInt(
      (new Date().getTime() - startTimestamp) / 1000,
      10
    ),
    day = Math.floor(offset / 86400),
    hour = Math.floor((offset % 86400) / 3600),
    minute = Math.floor(((offset % 86400) % 3600) / 60),
    second = Math.floor(((offset % 86400) % 3600) % 60);
  timeToNowDOM.innerHTML =
    day + "天" + hour + "小时" + minute + "分钟" + second + "秒";
  setTimeout(updateTimeStr, 500);
}

setTimeout(updateTimeStr, 500);
</script>


      <div class="back-to-top hidden">
  <span>
    <i class="iconfont icon-60"></i><span></span>%
  </span>
</div>

<script>
const updateIconToTop = percent => {
  let dom = document.querySelector(".back-to-top span span");
  dom.innerText = percent;
  if(percent < 1) {
    document.querySelector(".back-to-top").className = "back-to-top hidden";
  } else {
    document.querySelector(".back-to-top").className = "back-to-top";
  }
}

const handleScoll = () => {
  let isRunning = false;
  return () => {
    if (isRunning) return;
    isRunning = true;
    window.requestAnimationFrame(timestamp => {
      let scrollTop =
          document.documentElement.scrollTop || document.body.scrollTop,
        scrollHeight =
          document.documentElement.scrollHeight ||
          document.body.scrollHeight,
        clientHeight =
          document.documentElement.clientHeight ||
          document.body.clientHeight;
      isRunning = false;
      if (scrollTop <= 1) {
        updateIconToTop(0);
        return;
      }
      if (scrollTop + clientHeight >= scrollHeight) {
        updateIconToTop(100);
      } else {
        updateIconToTop(parseInt(
          100 * scrollTop / (scrollHeight - clientHeight),
          10
        ));
      }
    });
  };
}

const backToTop = () => {
  let scrollTop =
      document.documentElement.scrollTop || document.body.scrollTop,
    delay = 10,
    time = 200;
  if (scrollTop <= 20) {
    document.documentElement.scrollTop = 0;
    document.body.scrollTop = 0;
    return;
  }
  let step = Math.ceil(scrollTop * delay / time);
  let timer = setInterval(() => {
    scrollTop =
      document.documentElement.scrollTop || document.body.scrollTop;
    if (scrollTop - step <= 0) {
      document.documentElement.scrollTop = 0;
      document.body.scrollTop = 0;
      clearInterval(timer);
    } else {
      document.documentElement.scrollTop = scrollTop - step;
      document.body.scrollTop = scrollTop - step;
    }
  }, delay);
}

document.addEventListener("scroll", handleScoll(), false);

document.querySelector(".back-to-top").addEventListener("click", backToTop, false);

</script>

    </div>

    
      <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
<script>
  (() => {
    const mathjaxConfig = {
      showProcessingMessages: false, //关闭js加载过程信息
      messageStyle: "none", //不显示信息
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
        displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
        skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
      },
      "HTML-CSS": {
        availableFonts: ["STIX", "TeX"], //可选字体
        showMathMenu: false //关闭右击菜单显示
      }
    }

    let mathjaxInterval = setInterval(() => {
      if(!window.MathJax){
        return;
      }
      window.MathJax.Hub.Config(mathjaxConfig)
      window.MathJax.Hub.Queue(["Typeset", MathJax.Hub, document.getElementById('app')])

      clearInterval(mathjaxInterval)
    }, 10)    
  })()
</script>
    

    <script src="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script>
<script async>
  let fancyTimer = setInterval(function(){
    if(!window.$){
      return;
    }
    $(document).ready(function() {
      $(".post img").each(function () {
        if($(this).parent().get(0).tagName.toLowerCase() === "a") {
          return;
        }
        // $(this).attr("data-fancybox", "gallery"); // if you add 'data-fancybox', img will display after showed
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "gallery");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      });
      
      clearInterval(fancyTimer);
    });
  }, 10);
</script>

    
  </body>

</html>
